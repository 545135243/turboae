__author__ = 'yihanjiang'
# Benchmarks



# rate= 1/2
rate2_ltetbcc_bl64_snrs = [0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]
rate2_ltetbcc_bl64_bler = [0.565,0.3632, 0.216, 0.1045, 0.0412333333333333, 0.0142, 0.0042, 0.00102380952380952,
                           0.000245238095238095, 0.0000634146341463415,0.000011 ]


rate2_ploar_list8_bl64_snrs  = [0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0]
rate2_ploar_list8_bl64_bler  = [0.6115,0.3905, 0.2385, 0.1013, 0.0362, 0.00873333333333333, 0.00134375, 0.000157, 0.000006 ]

rate2_ploar_list32_bl64_snrs = [0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5]
rate2_ploar_list32_bl64_bler = [0.5105,0.2815, 0.1486, 0.0535, 0.015, 0.00255, 0.000367272727272727, 	0.000027 ]



# dynamcis


traj = [0.03832480311393738, 0.017496798187494278, 0.014807996340095997, 0.013850998133420944, 0.013430200517177582, 0.012965798377990723, 0.012765196152031422, 0.01271919533610344, 0.012707799673080444, 0.012672198936343193, 0.012585599906742573, 0.012626797892153263, 0.012610995210707188, 0.012612400576472282, 0.012622799724340439, 0.012765000574290752, 0.012521599419414997, 0.012602199800312519, 0.012524798512458801, 0.012683600187301636, 0.012606795877218246, 0.012627198360860348, 0.012592802755534649, 0.012526798993349075, 0.012618803419172764, 0.012515404261648655, 0.012508001178503036, 0.01258939504623413, 0.01258660014718771, 0.012542201206088066, 0.012571800500154495, 0.012640196830034256, 0.012624000199139118, 0.012590598315000534, 0.012624997645616531, 0.012497800402343273, 0.012591400183737278, 0.012542201206088066, 0.012538199312984943, 0.012485201470553875, 0.012604400515556335, 0.012560799717903137, 0.012601594440639019, 0.012514001689851284, 0.012505599297583103, 0.012555399909615517, 0.01255860086530447, 0.012627998366951942, 0.012479398399591446, 0.012592397630214691, 0.012650801800191402, 0.012495200149714947, 0.012558598071336746, 0.012657196260988712, 0.012548196129500866, 0.0125842010602355, 0.012554200366139412, 0.012606801465153694, 0.012661399319767952, 0.012549200095236301, 0.012552795931696892, 0.012498000636696815, 0.01251219678670168, 0.012524601072072983, 0.012545999139547348, 0.01251679752022028, 0.012609201483428478, 0.012543202377855778, 0.012502198107540607, 0.012552602216601372, 0.0124984011054039, 0.012444799765944481, 0.012540796771645546, 0.012550598941743374, 0.012524998746812344, 0.0125465989112854, 0.012629600241780281, 0.012508198618888855, 0.012386400252580643, 0.01249520294368267, 0.012421801686286926, 0.012416401877999306, 0.012356800027191639, 0.012300798669457436, 0.012202801182866096, 0.012119200080633163, 0.011946799233555794, 0.011943800374865532, 0.01165239792317152, 0.011520803906023502, 0.011358997784554958, 0.011340197175741196, 0.011152001097798347, 0.010891600511968136, 0.010636799037456512, 0.0103500010445714, 0.01008359994739294, 0.009959802031517029, 0.009548000991344452, 0.0091804014518857, 0.008830801583826542, 0.00839839968830347, 0.008195600472390652, 0.007738797925412655, 0.007550999987870455, 0.007222600281238556, 0.006899799685925245, 0.006879999302327633, 0.006473801098763943, 0.006247200071811676, 0.006033999379724264, 0.005916798487305641, 0.005697599612176418, 0.005602000281214714, 0.005537000019103289, 0.005412599537521601, 0.005268401931971312, 0.0051130009815096855, 0.005172399338334799, 0.005035400856286287, 0.004986399784684181, 0.004908999893814325, 0.004924799781292677, 0.004908000119030476, 0.004980600439012051, 0.004872600082308054, 0.0047693997621536255, 0.004809599835425615, 0.0047690002247691154, 0.004731400869786739, 0.004857598338276148, 0.004780401010066271, 0.00471879867836833, 0.004828199744224548, 0.004802399314939976, 0.004822799935936928, 0.004818400368094444, 0.004765200428664684, 0.004700798541307449, 0.004732999484986067, 0.004770800471305847, 0.004707000218331814, 0.004829800687730312, 0.004717999137938023, 0.004712000489234924, 0.004694798961281776, 0.004707798827439547, 0.004747199360281229, 0.0047323997132480145, 0.0047519998624920845, 0.004729000385850668, 0.004706001374870539, 0.00472320057451725, 0.004709199070930481, 0.004661800339818001, 0.004667400382459164, 0.0047599999234080315, 0.004694799892604351, 0.00466479966416955, 0.004677199758589268, 0.004745999351143837, 0.004676200915127993, 0.004701000172644854, 0.004619799554347992, 0.004665599204599857, 0.004646600224077702, 0.004595200065523386, 0.0046057989820837975, 0.004596999380737543, 0.004506799858063459, 0.004622000269591808, 0.004538599867373705, 0.00445080129429698, 0.004424200393259525, 0.004449799191206694, 0.004387798719108105, 0.004353801254183054, 0.004269599914550781, 0.004286400508135557, 0.004138398915529251, 0.004089199937880039, 0.004107400309294462, 0.004011199343949556, 0.0039993999525904655, 0.003954599611461163, 0.003854199778288603, 0.0038654000964015722, 0.003761600237339735, 0.0037329988554120064, 0.003660600632429123, 0.003603999735787511, 0.0035555996000766754, 0.003444400615990162, 0.003333800006657839, 0.003094799816608429, 0.0029709991067647934, 0.002914999844506383, 0.0027109996881335974, 0.002526000142097473, 0.0023987996391952038, 0.002221999689936638, 0.00207659974694252, 0.0018813996575772762, 0.001776599558070302, 0.0015437999973073602, 0.0013797999126836658, 0.0012197999749332666, 0.0011640001321211457, 0.0010412000119686127, 0.0009968000231310725, 0.0010134000331163406, 0.0008918001549318433, 0.0008808000129647553, 0.0008249999373219907, 0.000843200134113431, 0.0008025999995879829, 0.0007873997674323618, 0.0007778001599945128, 0.0009459999273531139, 0.0008107998874038458, 0.0007441997877322137, 0.0007506001857109368, 0.0007183998823165894, 0.0007081999210640788, 0.0006893998943269253, 0.0006750000757165253, 0.0006992000271566212, 0.000649399880785495, 0.0006622000364586711, 0.0006423999438993633, 0.0007070000283420086, 0.0006654001772403717, 0.0006339999381452799, 0.0006741999532096088, 0.0006195999449118972, 0.0006562001071870327, 0.0006352000636979938, 0.0006274001207202673, 0.0006181998760439456, 0.0006181999342516065, 0.0005994000239297748, 0.0006063999608159065, 0.0005860000965185463, 0.0005895998911000788, 0.0006213998422026634, 0.0005851999158039689, 0.0005961998249404132, 0.000831599987577647, 0.0006681999657303095, 0.0006161999772302806, 0.0006477998686023057, 0.0006263999384827912, 0.000614199903793633, 0.0005653999396599829, 0.0005797999328933656, 0.0005246000364422798, 0.0005565998726524413, 0.0005779998027719557, 0.0005457999068312347, 0.000562199973501265, 0.00052579992916435, 0.0005255999858491123, 0.0005079999100416899, 0.0005061998963356018, 0.0004791999817825854, 0.0005446000141091645, 0.0004918000195175409, 0.00047480000648647547, 0.0005323999212123454, 0.0005199998850002885, 0.0004931999719701707, 0.00043639997602440417, 0.00046500004827976227, 0.00046800001291558146, 0.0004975999472662807, 0.0004950000438839197, 0.00046720000682398677, 0.00042899997788481414, 0.000443800090579316, 0.0004524000396486372, 0.00044819992035627365, 0.0004799999878741801, 0.0008001999231055379, 0.0007025998784229159, 0.0005984000163152814, 0.0004883999354206026, 0.00044139998499304056, 0.0004274000821169466, 0.00043560005724430084, 0.0004087999986950308, 0.00038279994623735547, 0.000434999936260283, 0.00042320010834373534, 0.00036260008346289396, 0.000378799915779382, 0.00037359996349550784, 0.00037720007821917534, 0.0003712000616360456, 0.00035539991222321987, 0.00036559998989105225, 0.00038979999953880906, 0.0003387999895494431, 0.00033220002660527825, 0.00035620006383396685, 0.00036139998701401055, 0.00034400008735246956, 0.0003185999230481684, 0.00034040005994029343, 0.0004168000305071473, 0.0003592001157812774, 0.0003535999567247927, 0.0003116000152658671, 0.00032199997804127634, 0.0003218000056222081, 0.00031440003658644855, 0.0002982000296469778, 0.0003615999885369092, 0.0003338000096846372, 0.00030419998802244663, 0.0003606000100262463, 0.00031640002271160483, 0.0003687999560497701, 0.0003252000315114856, 0.0003276000206824392, 0.00031300002592615783, 0.0003154000442009419, 0.0002702000201679766, 0.0002779999631457031, 0.00027379998937249184, 0.00028700000257231295, 0.0002817999629769474, 0.0002838000364135951, 0.0003277999931015074, 0.0002982000296469778, 0.00028459992608986795, 0.0002992000081576407, 0.00028760003624483943, 0.00035300003946758807, 0.0002733999863266945, 0.0002954000374302268, 0.0002599999716039747, 0.0002917999809142202, 0.0002940000267699361, 0.00029759996687062085, 0.0003079999587498605, 0.00040940000326372683, 0.00028540007770061493, 0.0002570000069681555, 0.00026980001712217927, 0.0002713998837862164, 0.0002578000130597502, 0.00027899991255253553, 0.0002703999634832144, 0.0002452000044286251, 0.0002607999776955694, 0.00026179998531006277, 0.0002497999812476337, 0.00023199997667688876, 0.00025359998107887805, 0.0002449999446980655, 0.00026279999292455614, 0.00028840001323260367, 0.00025540002388879657, 0.0002860000531654805, 0.0002664000785443932, 0.00024980001035146415, 0.0003133999998681247, 0.0003179999766871333, 0.0002593999379314482, 0.00027320001390762627, 0.00025220002862624824, 0.0003184000088367611, 0.0002733998990152031, 0.0002586000773590058, 0.00024960003793239594, 0.00032520006061531603, 0.00028059998294338584, 0.0002770000428427011, 0.00026700005400925875, 0.0002443999983370304, 0.00024640001356601715, 0.00024380003742408007, 0.00026080006500706077, 0.00021999998716637492, 0.0002516000240575522, 0.00023460002557840198, 0.00021120002202223986, 0.0002891999902203679, 0.0002631999959703535, 0.0002536000101827085, 0.000219000008655712, 0.00021159998141229153, 0.00020180008141323924, 0.0002194000408053398, 0.00020899999071843922, 0.00021159995230846107, 0.00030500005232170224, 0.00026740002795122564, 0.0002440000098431483, 0.00021179999748710543]


# BERs

'''
saved model ./tmp/torch_model_321575.pt
yihan@hilbert:~/NeurIPS_DTA_package$ CUDA_VISIBLE_DEVICES=2 python3.6 main.py  -encoder dta_rate2_rnn -decoder dta_rate2_rnn -enc_num_unit 100 -dec_num_unit 100 -block_len 100  -num_iter_ft 5 -channel awgn -num_train_dec 5 -num_train_enc 1 -code_rate_k 1 -code_rate_n 2 -group_norm_g 1 -train_channel_low 4.0 -train_channel_high 4.0  -snr_test_start 0.0 -snr_test_end 8.0 -snr_points 9 -num_iteration 6  -is_parallel 1  -train_dec_channel_low 0.0 -train_dec_channel_high 4.0  -group_norm_g 1 -is_same_interleaver 1 -num_train_enc 1  -num_train_dec 5 -dec_lr 0.0001 -enc_lr 0.0001  -num_block 50000 -batch_size 500 -train_channel_mode group_norm -test_channel_mode group_norm -num_epoch 400 --print_test_traj
'''
# final results on SNRs  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]
# BER [0.19607499241828918, 0.07957179844379425, 0.015661194920539856, 0.0017812001751735806, 0.00023460005468223244, 4.160000025876798e-05, 3.800000513365376e-06, 9.999999974752427e-07, 0.0]
# BLER [0.937, 0.6829200000000002, 0.28613999999999995, 0.07333999999999999, 0.01624000000000001, 0.003420000000000002, 0.00036000000000000013, 8e-05, 0.0]


# plots

import matplotlib.pylab as plt

plt.figure(1)
plt.yscale('log')
plt.plot(traj)

plt.show()